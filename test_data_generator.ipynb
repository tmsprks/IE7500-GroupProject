{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afec2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\life\\edu\\NU-DAE\\IE 7500 - NLP\\Proj\\venv-nlp-proj\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from sa_data_factory import SADataFactory\n",
    "from data_generator import DataGenerator\n",
    "from kaggle_data_loader import KaggleDataLoader\n",
    "from kaggle_dataset import KaggleDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06265db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User0n3\\.cache\\kagglehub\\datasets\\kritanjalijain\\amazon-reviews\\versions\\2\n",
      "C:\\Users\\User0n3\\.cache\\kagglehub\\datasets\\kritanjalijain\\amazon-reviews\\versions\\2\n",
      "['amazon_review_polarity_csv.tgz', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "kaggle_path = \"kritanjalijain/amazon-reviews\"\n",
    "kaggle_data_loader = KaggleDataLoader(kaggle_path)\n",
    "kaggle_data_loader.load_data(KaggleDataSet.get_kaggle_column_names())\n",
    "\n",
    "kaggle_dataset = KaggleDataSet(kaggle_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b4b6df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label count:\n",
      " Kaggle_Label\n",
      "2    1800000\n",
      "1    1800000\n",
      "Name: count, dtype: int64\n",
      "Test label count:\n",
      " Kaggle_Label\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_label_count = kaggle_dataset.get_train_value_count()\n",
    "test_label_count = kaggle_dataset.get_test_value_count()\n",
    "print(\"Train label count:\\n\", train_label_count)\n",
    "print(\"Test label count:\\n\", test_label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa43543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train_2K.csv from train dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "1    1440119\n",
      "2    1439881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'train_2K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    1000\n",
      "2    1000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (2000, 3)\n",
      "\n",
      "Processing train_50K.csv from train dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "1    1440119\n",
      "2    1439881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'train_50K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    25000\n",
      "2    25000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (50000, 3)\n",
      "\n",
      "Processing train_60K.csv from train dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "1    1440119\n",
      "2    1439881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'train_60K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    30000\n",
      "2    30000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (60000, 3)\n",
      "\n",
      "Processing test_1K.csv from test dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'test_1K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    500\n",
      "2    500\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (1000, 3)\n",
      "\n",
      "Processing test_10K.csv from test dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'test_10K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    5000\n",
      "2    5000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (10000, 3)\n",
      "\n",
      "Processing test_20K.csv from test dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    200000\n",
      "1    200000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'test_20K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    10000\n",
      "2    10000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (20000, 3)\n",
      "\n",
      "Processing validate_1K.csv from validation dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    360119\n",
      "1    359881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'validate_1K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    500\n",
      "2    500\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (1000, 3)\n",
      "\n",
      "Processing validate_10K.csv from validation dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    360119\n",
      "1    359881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'validate_10K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    5000\n",
      "2    5000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (10000, 3)\n",
      "\n",
      "Processing validate_20K.csv from validation dataset\n",
      "Label counts:\n",
      " Kaggle_Label\n",
      "2    360119\n",
      "1    359881\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset saved to 'validate_20K.csv', ensure uniqueness across dataset type: True, randomize samples: False\n",
      "Downsampled dataset label counts:\n",
      " Kaggle_Label\n",
      "1    10000\n",
      "2    10000\n",
      "Name: count, dtype: int64\n",
      "Downsampled dataset size: (20000, 3)\n",
      "\n",
      "\n",
      "File generations completed\n"
     ]
    }
   ],
   "source": [
    "sa_data_factory = SADataFactory(kaggle_dataset)   \n",
    "generator = DataGenerator(sa_data_factory)\n",
    "results = generator.generate_datasets(ensure_uniqueness_across_same_dataset_type=True, randomize_samples=False)\n",
    "print(\"\\n\\nFile generations completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b826d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data files generated: 9\n",
      "\n",
      "\n",
      "Generated train_2K.csv, ensure uniqueness True, randomize samples False with 2000 rows\n",
      "   Kaggle_Label                                          Title  \\\n",
      "0             1  This will attach to the wall, but not your TV   \n",
      "1             1            I really wanted to like this cd....   \n",
      "\n",
      "                                              Review  \n",
      "0  You have to buy another part that attaches to ...  \n",
      "1  I've been a fan of Lou Reeds for a long time. ...  \n",
      "\n",
      "Generated train_50K.csv, ensure uniqueness True, randomize samples False with 50000 rows\n",
      "   Kaggle_Label                                              Title  \\\n",
      "0             1                                   Not recommended.   \n",
      "1             1  Right up there w//Little Women as Worst Book Ever   \n",
      "\n",
      "                                              Review  \n",
      "0  If it wasn't for Case knives it wouldn't be mu...  \n",
      "1  I was forced into reading this in class this y...  \n",
      "\n",
      "Generated train_60K.csv, ensure uniqueness True, randomize samples False with 60000 rows\n",
      "   Kaggle_Label           Title  \\\n",
      "0             1   Pink Yawnfest   \n",
      "1             1  Pure Posturing   \n",
      "\n",
      "                                              Review  \n",
      "0  It's frustrating when screenwriters, journalis...  \n",
      "1  Anyone who goes to a Fugazi show (in DC) knows...  \n",
      "\n",
      "Generated test_1K.csv, ensure uniqueness True, randomize samples False with 1000 rows\n",
      "   Kaggle_Label                  Title  \\\n",
      "0             1  So where's the \"fun\"?   \n",
      "1             1        product quality   \n",
      "\n",
      "                                              Review  \n",
      "0  What kind of a cheap @$$ game is this?! It's n...  \n",
      "1  it is impossible to cram it down any drain, I ...  \n",
      "\n",
      "Generated test_10K.csv, ensure uniqueness True, randomize samples False with 10000 rows\n",
      "   Kaggle_Label                     Title  \\\n",
      "0             1            Colored People   \n",
      "1             1  Don't waste your time!!!   \n",
      "\n",
      "                                              Review  \n",
      "0  The book \"Colored People\" is a good book for a...  \n",
      "1  This is an example of one bad apple. A $5.00 b...  \n",
      "\n",
      "Generated test_20K.csv, ensure uniqueness True, randomize samples False with 20000 rows\n",
      "   Kaggle_Label                                              Title  \\\n",
      "0             1                      I haven't got my magazine yet   \n",
      "1             1  Bruce, you couldnt have picked a worse scrpit ...   \n",
      "\n",
      "                                              Review  \n",
      "0  I never received a copy of this magazine i am ...  \n",
      "1  This was honestly one of the worst movies i ha...  \n",
      "\n",
      "Generated validate_1K.csv, ensure uniqueness True, randomize samples False with 1000 rows\n",
      "   Kaggle_Label                                Title  \\\n",
      "0             1  1 star cause i can't give any lower   \n",
      "1             1                       moves too slow   \n",
      "\n",
      "                                              Review  \n",
      "0  Well, the lead single from this album says it ...  \n",
      "1  Those people that gave it a three were being k...  \n",
      "\n",
      "Generated validate_10K.csv, ensure uniqueness True, randomize samples False with 10000 rows\n",
      "   Kaggle_Label                                           Title  \\\n",
      "0             1                           A Bummer from Philips   \n",
      "1             1  This book should be burned just like Manderley   \n",
      "\n",
      "                                              Review  \n",
      "0  It looked great on paper and I had become used...  \n",
      "1  I was really excited when I found this book. I...  \n",
      "\n",
      "Generated validate_20K.csv, ensure uniqueness True, randomize samples False with 20000 rows\n",
      "   Kaggle_Label                                    Title  \\\n",
      "0             1  Do NOT read before bedtime. Depressing!   \n",
      "1             1                           cell batteries   \n",
      "\n",
      "                                              Review  \n",
      "0  An only, lonely child. Bullied at school. Clea...  \n",
      "1  I ordered two of these batteries for my cell p...  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data files generated: {len(results)}\\n\")\n",
    "for output_file, ensure_uniqueness, randomize_samples, df in results:\n",
    "    print(f\"\\nGenerated {output_file}, ensure uniqueness {ensure_uniqueness}, randomize samples {randomize_samples} with {len(df)} rows\")\n",
    "    print(df.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nlp-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
